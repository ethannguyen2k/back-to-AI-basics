{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0452816f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SimpleNeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        # Initialize weights and biases\n",
    "        self.W1 = np.random.randn(input_size, hidden_size) * 0.01\n",
    "        self.b1 = np.zeros((1, hidden_size))\n",
    "        self.W2 = np.random.randn(hidden_size, output_size) * 0.01\n",
    "        self.b2 = np.zeros((1, output_size))\n",
    "    \n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "    \n",
    "    def softmax(self, x):\n",
    "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        # First layer\n",
    "        self.z1 = np.dot(X, self.W1) + self.b1\n",
    "        self.a1 = self.relu(self.z1)\n",
    "        \n",
    "        # Output layer\n",
    "        self.z2 = np.dot(self.a1, self.W2) + self.b2\n",
    "        self.out = self.softmax(self.z2)\n",
    "        \n",
    "        return self.out\n",
    "    \n",
    "    def backward(self, X, y, learning_rate=0.01):\n",
    "        # Number of samples\n",
    "        m = X.shape[0]\n",
    "        \n",
    "        # Compute gradients\n",
    "        dZ2 = self.out - y\n",
    "        dW2 = np.dot(self.a1.T, dZ2) / m\n",
    "        db2 = np.sum(dZ2, axis=0, keepdims=True) / m\n",
    "        \n",
    "        dA1 = np.dot(dZ2, self.W2.T)\n",
    "        dZ1 = dA1 * (self.z1 > 0)\n",
    "        dW1 = np.dot(X.T, dZ1) / m\n",
    "        db1 = np.sum(dZ1, axis=0, keepdims=True) / m\n",
    "        \n",
    "        # Update weights and biases\n",
    "        self.W2 -= learning_rate * dW2\n",
    "        self.b2 -= learning_rate * db2\n",
    "        self.W1 -= learning_rate * dW1\n",
    "        self.b1 -= learning_rate * db1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b673812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6930\n",
      "Epoch 100, Loss: 0.6919\n",
      "Epoch 200, Loss: 0.6825\n",
      "Epoch 300, Loss: 0.6184\n",
      "Epoch 400, Loss: 0.4471\n",
      "Epoch 500, Loss: 0.3054\n",
      "Epoch 600, Loss: 0.1947\n",
      "Epoch 700, Loss: 0.1125\n",
      "Epoch 800, Loss: 0.0696\n",
      "Epoch 900, Loss: 0.0488\n"
     ]
    }
   ],
   "source": [
    "# Simple dataset: two clusters of points\n",
    "X = np.vstack([\n",
    "    np.random.randn(100, 2) + np.array([2, 2]),  # Class 0\n",
    "    np.random.randn(100, 2) + np.array([-2, -2])  # Class 1\n",
    "])\n",
    "y = np.hstack([np.zeros(100), np.ones(100)]).astype(int)\n",
    "\n",
    "# Create and train network\n",
    "nn = SimpleNeuralNetwork(input_size=2, hidden_size=3, output_size=2)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1000):\n",
    "    # Forward pass\n",
    "    pred = nn.forward(X)\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = -np.sum(np.log(pred[range(len(y)), y])) / len(y)\n",
    "\n",
    "    nn.backward(X, np.eye(2)[y], learning_rate=0.01)\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56efe9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1: [[-0.68148114  0.66099103  0.41560136]\n",
      " [-0.64816408  0.75636262  0.5073244 ]]\n",
      "b1: [[0.29751054 0.51102386 0.33072266]]\n",
      "W2: [[-0.68974308  0.70510598]\n",
      " [ 0.80325263 -0.79058361]\n",
      " [ 0.51936748 -0.51913441]]\n",
      "b2: [[-0.44384601  0.44384601]]\n"
     ]
    }
   ],
   "source": [
    "# Your weights and biases\n",
    "print(\"W1:\", nn.W1)\n",
    "print(\"b1:\", nn.b1)\n",
    "print(\"W2:\", nn.W2)\n",
    "print(\"b2:\", nn.b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212f79b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
